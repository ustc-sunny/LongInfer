# LongInfer is started with code
Introduce: LongInfer is an LLM inference framework with long context in consumer-grade GPU, like Nvidia RTX 4060. It optimizes KV Cache operations, parallelism, pipeline, etc.
